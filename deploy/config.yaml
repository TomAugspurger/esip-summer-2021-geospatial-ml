jupyterhub:
  proxy:
    https:
      enabled: true
      hosts:
        - "esip2021.westeurope.cloudapp.azure.com"
      letsencrypt:
        contactEmail: "taugspurger@microsoft.com"
    service:
      annotations:
        # Update this with your hub's name.
        service.beta.kubernetes.io/azure-dns-label-name: "esip2021"

  hub:
    # Disable hub network Policy, so that the dask gateway server API can reach the hub directly
    # Not required for dask-gateway>0.9.0
    # https://github.com/dask/helm-chart/issues/142
    networkPolicy:
      enabled: false

    # dask-gateway service added in secrets.yaml

    config:
      JupyterHub:
        authenticator_class: dummy
        # password is set in secrets.yaml

  singleuser:
    image:
      name: "mcr.microsoft.com/planetary-computer/python"
      tag: "2021.07.08.0"

    profileList:
      - display_name: "CPU"
        description: "Standard notebook server"
      - display_name: "GPU"
        description: "Notebook server with a GPU"
        kubespawner_override:
          extra_resource_limits:
            nvidia.com/gpu: "1"
            image: "mcr.microsoft.com/planetary-computer/gpu-pytorch:2021.07.08.0"

    extraEnv:
      DASK_GATEWAY__CLUSTER__OPTIONS__IMAGE: '{JUPYTER_IMAGE_SPEC}'
      DASK_DISTRIBUTED__DASHBOARD_LINK: '/user/{JUPYTERHUB_USER}/proxy/{port}/status'
      DASK_LABEXTENSION__FACTORY__MODULE: 'dask_gateway'
      DASK_LABEXTENSION__FACTORY__CLASS: 'GatewayCluster'

dask-gateway:
  gateway:
    # auth set in secrets.yaml
    backend:
      worker:
        # Ensure workers are scheduled on the worker pool
        extraPodConfig:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                - matchExpressions:
                  - key: "k8s.dask.org/dedicated"
                    operator: "In"
                    values:
                      - "worker"

          tolerations:
            # allow workers to be scheduled on the worker pool, which has preemptible nodes.
            - key: "k8s.dask.org/dedicated"
              operator: "Equal"
              value: "worker"
              effect: "NoSchedule"
            - key: "k8s.dask.org_dedicated"
              operator: "Equal"
              value: "worker"
              effect: "NoSchedule"
            - key: "kubernetes.azure.com/scalesetpriority"
              operator: "Equal"
              value: "spot"
              effect: "NoSchedule"

    extraConfig:
      01-optionHandler: |
          # Configure options to
          # 1. Have the default worker image match the singleuser image
          # 2. Place bounds on worker CPU and Memory requests
          # 3. Accept a mapping of environment variables to pass to workers.
          from dask_gateway_server.options import Options, Float, String, Mapping
          def cluster_options(user):
              def option_handler(options):
                  if ":" not in options.image:
                      raise ValueError("When specifying an image you must also provide a tag")

                  return {
                      "worker_cores": 0.88 * min(options.worker_cores / 2, 1),
                      "worker_cores_limit": options.worker_cores,
                      "worker_memory": "%fG" % (0.95 * options.worker_memory),
                      "worker_memory_limit": "%fG" % options.worker_memory,
                      "image": options.image,
                      "environment": options.environment,
                  }
              return Options(
                  Float("worker_cores", 1, min=1, max=16, label="Worker Cores"),
                  Float("worker_memory", 2, min=1, max=32, label="Worker Memory (GiB)"),
                  String("image", default="pangeo/pangeo-notebook:latest", label="Image"),
                  Mapping("environment", {}, label="Environment Variables"),
                  handler=option_handler,
              )
          c.Backend.cluster_options = cluster_options